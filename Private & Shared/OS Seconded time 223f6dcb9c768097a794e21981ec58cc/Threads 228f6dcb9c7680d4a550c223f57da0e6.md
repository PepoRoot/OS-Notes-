# Threads

# Are Threads useful on a single CPU ?

![image.png](Threads%20228f6dcb9c7680d4a550c223f57da0e6/image.png)

- if (t_idle)>2*(t_context_switch) then context switch two hide idling Time
- t-context-switch threads < t-context-switch process   hide latency

---

# multithreading OS kernel

- threads working on behalf of app
- at level services like demons or driverse

---

# What we need to support thread

- thread Data structure
    - identify threads, keep track of resource usage
- Mechanism to create and manage threads
- Mechanisms to safely coordinate among thread running concurrently in the same address space

---

# Threads and concurrency

The different between the process and thread in it if two process it will have virtual address mapping with different  physical address but each process will have different physical address in thread can have the same physical address for it 

---

# Mutula Exclusive

 

- exclusive access to only on thread at a time
- mutex

## Waiting on other threads

- specific condition before procession
- condition variable
- waking up other threads from wait state

---

# Thread and Thread Creation

## Thread type

- Thread data structure

## Fork (proc, args)

- creat a thread
- not unix fork

## Join

- terminate a threads

---

# Mutex

the lock operation meaning they will be suspended here , the y will not be able to proceed until the mutex owner the lock holder realse it 

---

# Condition variable

Should be conjunction with mutexes to control the behavior of concurrent threads  

---

## Condition Type

- wait (Mutex , cond)
    - mutex is Automatically realse and reacuried on wait
- signal (cond)
    - notify onlyone thread waiting on condition
- Broadcast (cond)
    - notify all waiting threads

---

# Avoiding common mistakes

- keep track mutex count variables used with a resources
- check that you are always using lock and unlock correctly
- use a single mutex to access single resources
- check that you are singling correct condition
- check that you are not using signal when broadcast is needed

---

# Dead lock

Two or more competing thread are waiting on each other to complete , but none of them ever do 

![image.png](Threads%20228f6dcb9c7680d4a550c223f57da0e6/5e10513a-3c1c-4b0b-9a15-95835d55d0ce.png)

They must lock mutexes that protect the shared variable  A and B , and lets say T1 first lock the Mutex A and then lock mutex B 

T2 first Mutex for B then Mutex A 

- The problem is the two threads waiting each other in a cycle neither one of the m will be able to get nether one of them in fact will be able to execute this second lock operation they’ll keep waiting each other and we’ll have dead lock

## How to Avoid it

- unlock A before Locking the B
    - Fine grained locking
    - but thread need both A and B
- get all locks upfront then realse at the end use one mega lock
    - too restrictive ==⇒ limits parallelism
    - for some application is Ok
- Maintain lock
    - First m-A
    - then m-B

## summery

a cycle in wait graph is necessary and sufficient for a dead lock to occur 

### what can we do about it ?

- Deadlock prevention =⇒ expensive
- Detection and Recovery =⇒ roll back
- Apply the ostrich algorithm ⇒ Do nothing

============⇒ if all else fails - just Reboot 

---

# **multithreading models**

## One to One mode :

thread that either is created or there is available kernel-level thread,  then kernel level thread is associated by user-level thread

OS sees / understands threads synchronization blocking

Must go to OS for all operations (may be expensive)

OS  may have limits on policies, thread

portability

## One to many model:

- all of the user level threads are supported are mapped to a single kernel level thread that’s means a thread managment library that decide which one the user level thread will be mapped to kernel level thread at any given point of time
- user level thread will run only once the kernel level thread is actually scheduled on the cpu

many to many :
Allow some user level  thread to be associated to with one kernel level process other perhaps to have one to one mapping with a process, so sort of the best of both world
The kernel know that the process is multithreaded since it has assigned multiple kernel level threads to it

---

# **Scope of Multithreading**

System Scope : system-wide thread management by OS-level thread managers

Process scope : user-level library manages threads within a single process

---

# Pattern multithreading

## Boss- workers pattern

Boss -Worker:
boss : assign work to workers
worker: performs entire task
Throughput of the system limited by boss thread ⇒ must keep boss efficient
Throughput = 1/boss_time_per_order
Boss assigns work by:
directly signaling specific worker
placing work in producer / consumer
workers don’t need to synchronize
Boss must track what each order is doing
Throughput will do down
Boss doesn’t need to know details about workers

---

how many workers 

- on demond
- pool of workers
- static vs dynamic

---

Boss Workers Vriants: 

- All workers created equal
- workers specialized for certain task

Better locality 

- OS management

---